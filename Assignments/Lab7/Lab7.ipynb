{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10605,
     "status": "ok",
     "timestamp": 1742800472978,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "v9mzQT73_9tv",
    "outputId": "2336fbe4-3c78-42a6-99e3-61f4141b5450"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1742800520555,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "MaFf0bSoAQnr",
    "outputId": "c9b52162-1aea-41cf-ecc8-939f51cd4ee8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1742800540760,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "OPdAMBxKAcKj",
    "outputId": "8a08e68e-f638-458e-bc1a-9b0875f420a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "gb = nltk.corpus.gutenberg\n",
    "print(\"Gutenberg files : \", gb.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1742800569252,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "CcB8QTsbAive"
   },
   "outputs": [],
   "source": [
    "macbeth = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1742800597997,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "-mpdoDyxAqGA",
    "outputId": "b10b52a9-4fd8-406f-95f7-e982037cb6a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1742800613325,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "TXwctkMaAuFG",
    "outputId": "c5da50d7-da76-4849-e355-9405459d5f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'The',\n",
       " 'Tragedie',\n",
       " 'of',\n",
       " 'Macbeth',\n",
       " 'by',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " '1603',\n",
       " ']']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1742800789097,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "_O5jkIrFBY3n",
    "outputId": "99b1e348-0bfd-430e-9392-efc274e2d56b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "23140\n",
      "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']']\n",
      "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ['Scoena', 'Prima', '.'], ['Thunder', 'and', 'Lightning', '.'], ['Enter', 'three', 'Witches', '.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the required data packages.\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') # Download punkt_tab for better sentence tokenization.\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# Access the Gutenberg corpus.\n",
    "gb = nltk.corpus.gutenberg\n",
    "print(\"Gutenberg files : \", gb.fileids())\n",
    "\n",
    "# Get words from Macbeth.\n",
    "macbeth = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "print(len(macbeth))\n",
    "print(macbeth[:10])\n",
    "\n",
    "# Get sentences from Macbeth using the Punkt sentence tokenizer.\n",
    "macbeth_sents = nltk.corpus.gutenberg.sents('shakespeare-macbeth.txt')\n",
    "print(macbeth_sents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1742800814481,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "gBX-h2XqBcB8",
    "outputId": "e58e3bf1-dd7c-4645-88fa-91e0acfa9c89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[',\n",
       "  'The',\n",
       "  'Tragedie',\n",
       "  'of',\n",
       "  'Macbeth',\n",
       "  'by',\n",
       "  'William',\n",
       "  'Shakespeare',\n",
       "  '1603',\n",
       "  ']'],\n",
       " ['Actus', 'Primus', '.'],\n",
       " ['Scoena', 'Prima', '.'],\n",
       " ['Thunder', 'and', 'Lightning', '.'],\n",
       " ['Enter', 'three', 'Witches', '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sents = nltk.corpus.gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1742800860485,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "vxB1jelrBpE_",
    "outputId": "5be36557-26ce-4897-93be-70ce9c08b95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 3 of 3 matches:\n",
      "nts with Dishes and Seruice ouer the Stage . Then enter Macbeth Macb . If it we\n",
      "with mans Act , Threatens his bloody Stage : byth ' Clock ' tis Day , And yet d\n",
      " struts and frets his houre vpon the Stage , And then is heard no more . It is \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(macbeth)\n",
    "text.concordance('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1742800915819,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "XBgwPgEiB0S_",
    "outputId": "6cf25472-0498-4b12-b32d-ea7bcbdd1c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_. bloody_: the_,\n"
     ]
    }
   ],
   "source": [
    "text.common_contexts(['Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1742800957209,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "QEMY_8cACBKB",
    "outputId": "79e78025-bd7d-4403-881b-888a4915a819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day time face warre ayre king bleeding man reuolt serieant like\n",
      "knowledge broyle shew head spring heeles hare thane skie\n"
     ]
    }
   ],
   "source": [
    "text.similar('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1742801000160,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "sho1jverCMVw",
    "outputId": "4f3e7415-b303-4263-8edb-853ab32d9326"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1962),\n",
       " ('.', 1235),\n",
       " (\"'\", 637),\n",
       " ('the', 531),\n",
       " (':', 477),\n",
       " ('and', 376),\n",
       " ('I', 333),\n",
       " ('of', 315),\n",
       " ('to', 311),\n",
       " ('?', 241)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(macbeth)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1742801027532,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "fcep4pM2CSDT",
    "outputId": "6ff56210-2af4-421e-ba0c-8a73c280a6e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1742801066749,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "VNnuGiYKCbzA",
    "outputId": "013bcd74-67d8-4502-e94e-ace5901140ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ll',\n",
       " 'are',\n",
       " \"didn't\",\n",
       " \"you'd\",\n",
       " 'yourself',\n",
       " 'own',\n",
       " 'm',\n",
       " 'have',\n",
       " 'didn',\n",
       " \"hasn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "print(len(sw))\n",
    "list(sw)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1742801114081,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "bLOc1xh5CnGu",
    "outputId": "39f11b94-08e0-4364-eb33-10dc3bc89ada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14946"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_filtered = [w for w in macbeth if w.lower() not in sw]\n",
    "len(macbeth_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742801146650,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "RXAUHQz2CuBh",
    "outputId": "bbd0de05-703f-4290-fe10-e5493f44b2d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1962),\n",
       " ('.', 1235),\n",
       " (\"'\", 637),\n",
       " (':', 477),\n",
       " ('?', 241),\n",
       " ('Macb', 137),\n",
       " ('haue', 117),\n",
       " ('-', 100),\n",
       " ('Enter', 80),\n",
       " ('thou', 63)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(macbeth_filtered)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742801206983,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "7_dC4k_vC48d",
    "outputId": "931cce31-2abf-4d0c-9ca9-30f5ce429995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('macb', 137),\n",
       " ('haue', 122),\n",
       " ('thou', 90),\n",
       " ('enter', 81),\n",
       " ('shall', 68),\n",
       " ('macbeth', 62),\n",
       " ('vpon', 62),\n",
       " ('thee', 61),\n",
       " ('macd', 58),\n",
       " ('vs', 57)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuation = set(string.punctuation)\n",
    "macbeth_filtered2 = [w.lower() for w in macbeth if w.lower() not in sw and w.lower() not in punctuation]\n",
    "fd = nltk.FreqDist(macbeth_filtered2)\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1742801241965,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "4WKOwgQTDF37",
    "outputId": "84676bbb-c919-4127-b1a8-fe0022eb92ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assassination',\n",
       " 'Chamberlaines',\n",
       " 'Distinguishes',\n",
       " 'Gallowgrosses',\n",
       " 'Metaphysicall',\n",
       " 'Northumberland',\n",
       " 'Voluptuousnesse',\n",
       " 'commendations',\n",
       " 'multitudinous',\n",
       " 'supernaturall',\n",
       " 'vnaccompanied']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_words = [w for w in macbeth if len(w)> 12]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1742801272686,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "NdG-GDyeDMhK",
    "outputId": "2a025f69-e685-4630-8e9f-dfe59e2f16da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Auaricious',\n",
       " 'Gracious',\n",
       " 'Industrious',\n",
       " 'Iudicious',\n",
       " 'Luxurious',\n",
       " 'Malicious',\n",
       " 'Obliuious',\n",
       " 'Pious',\n",
       " 'Rebellious',\n",
       " 'compunctious',\n",
       " 'furious',\n",
       " 'gracious',\n",
       " 'pernicious',\n",
       " 'pernitious',\n",
       " 'pious',\n",
       " 'precious',\n",
       " 'rebellious',\n",
       " 'sacrilegious',\n",
       " 'serious',\n",
       " 'spacious',\n",
       " 'tedious']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ious_words = [w for w in macbeth if 'ious' in w]\n",
    "ious_words = set(ious_words)\n",
    "sorted(ious_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742801313168,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "7f3nd8hqDYBj",
    "outputId": "98180cb2-9f69-4a32-edd5-883c550b0af3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('enter', 'macbeth'), 16),\n",
       " (('exeunt', 'scena'), 15),\n",
       " (('thane', 'cawdor'), 13),\n",
       " (('knock', 'knock'), 10),\n",
       " (('st', 'thou'), 9),\n",
       " (('thou', 'art'), 9),\n",
       " (('lord', 'macb'), 9),\n",
       " (('haue', 'done'), 8),\n",
       " (('macb', 'haue'), 8),\n",
       " (('good', 'lord'), 8),\n",
       " (('let', 'vs'), 7),\n",
       " (('enter', 'lady'), 7),\n",
       " (('wee', 'l'), 7),\n",
       " (('would', 'st'), 6),\n",
       " (('macbeth', 'macb'), 6)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrms = nltk.FreqDist(nltk.bigrams(macbeth_filtered2))\n",
    "bgrms.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1742801344789,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "fLaKEZiODfM4",
    "outputId": "c9d45479-c7bc-437e-9004-80cccd4b25fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('knock', 'knock', 'knock'), 6),\n",
       " (('enter', 'macbeth', 'macb'), 5),\n",
       " (('enter', 'three', 'witches'), 4),\n",
       " (('exeunt', 'scena', 'secunda'), 4),\n",
       " (('good', 'lord', 'macb'), 4),\n",
       " (('three', 'witches', '1'), 3),\n",
       " (('exeunt', 'scena', 'tertia'), 3),\n",
       " (('thunder', 'enter', 'three'), 3),\n",
       " (('exeunt', 'scena', 'quarta'), 3),\n",
       " (('scena', 'prima', 'enter'), 3)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgrms = nltk.FreqDist(nltk.trigrams (macbeth_filtered2))\n",
    "tgrms.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1742801381506,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "dESeJTAMDn5b",
    "outputId": "5e607413-52f5-481d-e0c3-e0d489ba849b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1742801528565,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "j6STnfdWD1-Q",
    "outputId": "d57b503f-b26a-4b46-a54d-a4086d1ad534"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf-8-sig')\n",
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2471,
     "status": "ok",
     "timestamp": 1742801563190,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "0kuwdMqcEVAi",
    "outputId": "36310218-bc18-463d-b66d-61f6d6798797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '*',\n",
       " '*',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " '2554',\n",
       " '*',\n",
       " '*']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize (raw)\n",
    "webtext = nltk.Text (tokens)\n",
    "webtext[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1742801623998,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "EFyH2spwEVCQ",
    "outputId": "a460cb6e-f058-49d7-b202-c244140c3688"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\r\\n<html>\\r\\n<hea'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1742801654829,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "HXJLOL0KEsRA"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, \"lxml\").get_text()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1742801693501,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "P9oqgb4nEypq",
    "outputId": "448024ed-8812-4715-ddd4-3d1b0e9edab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 2576,
     "status": "ok",
     "timestamp": 1742801774023,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "AjzsrS5aE9V2"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "reviews = nltk.corpus.movie_reviews\n",
    "documents = [(list(reviews.words(fileid)), category)\n",
    "for category in reviews.categories()\n",
    "for fileid in reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1742801805279,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "JFtF9zhuFP_9",
    "outputId": "de99de7d-6753-4bfd-8722-6caf62f2b1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surrounded by hype , high hopes , and the promise of an over - the - top performance by clueless ' s brittany murphy , don ' t say a word looked full of promise . hell , when i hear that \" i ' ll never tell \" whisper on the tv commercial , goose bumps run up my spine . alas , word is filled with little but disappointment , a kooky mix of girl , interrupted and ransom , with michael douglas and company collecting a paycheck to plod through a vapid and dull kidnapping thriller . douglas stars as nathan conrad , renowned new york psychologist , devoted father of jessie conrad ( skye mccole bartusiak ) , and loving husband to aggie conrad ( famke janssen ) . after a gang of jewel thieves , headed by sean bean ' s koster , kidnaps his daughter , nathan is forced to extract from his new patient , the catatonic and violent elisabeth burrows ( murphy ) , the location of some hidden bank job booty that her father hid from the koster gang a decade ago . but with hard - nosed detective sandra cassidy ( jennifer esposito , doing her best j . lo impression ) tracking down koster and his gang of hoodlums , the stakes are raised as nathan races against the clock to crack the mystery of elisabeth ' s head in order to get the goods inside . the catch - nathan only has until five o ' clock to solve the puzzle ! whoa , the suspense is almost too much . don ' t say a word loses the audience inside of 15 minutes . murphy looks and acts like linda blair from the exorcist during the first part of the movie , then turns around and reprises like her role from girl , interrupted . and the only real \" crazy \" to be found in the film is director gary fleder ' s ( things to do in denver when you ' re dead ) staggering use of flashback sequences . oliver platt , famke janssen , and even sean bean are decent actors , but the stuff they are given here -- such as a bedridden wife fighting off the token black guy with her crutch -- is insulting and demeaning . additionally , the use of the surveillance cameras and laptops to track nathan ' s every move is downright unbelievable . how do ex - cons fresh out of the big house afford all this equipment ? despite its flaws , don ' t say a word is surprisingly some of the best mainstream film you ' ll find this month -- and audiences will lap it up . americans love lukewarm , half - baked thrillers starring big names and accompanied by cheap thrills . someone get me my lithium !\n"
     ]
    }
   ],
   "source": [
    "first_review = ' '.join(documents[0][0])\n",
    "print(first_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1742801844255,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "FvSCNKEQFZyy",
    "outputId": "14ed89d8-0e8b-4894-e507-e5264974e59c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 3377,
     "status": "ok",
     "timestamp": 1742801877251,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "EqST4yc2FgF1"
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in reviews.words())\n",
    "word_features = list(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742801927187,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "zgCfeo2WFpDw"
   },
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    " document_words = set(document)\n",
    " features = {}\n",
    " for word in word_features:\n",
    "    features['{}'.format(word)] = (word in document_words)\n",
    " return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31912,
     "status": "ok",
     "timestamp": 1742802039431,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "lkyMIybBF-5T",
    "outputId": "e8106784-d7d3-4156-fd16-6e04f5c3fa3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(document_features(d,word_features), c) for (d,c) in documents]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 34722,
     "status": "ok",
     "timestamp": 1742802124515,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "FijCjz3WGWzk"
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[1500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98338,
     "status": "ok",
     "timestamp": 1742802253925,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "lgYcqNriGlaE",
    "outputId": "6ae4d3d6-e1be-44da-fc74-46493ca60a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "train_set, est_set = featuresets[1500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1742802633769,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "hapPJ27jIbfN",
    "outputId": "153ceb84-dcef-41c6-e97c-b44bf0e60d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               portrayal = True              pos : neg    =     18.2 : 1.0\n",
      "           uninteresting = True              neg : pos    =     10.0 : 1.0\n",
      "                    zero = True              neg : pos    =      9.4 : 1.0\n",
      "                    lame = True              neg : pos    =      8.7 : 1.0\n",
      "           controversial = True              pos : neg    =      8.6 : 1.0\n",
      "                    bore = True              neg : pos    =      8.1 : 1.0\n",
      "                    anna = True              pos : neg    =      7.9 : 1.0\n",
      "                 freedom = True              pos : neg    =      7.9 : 1.0\n",
      "              remembered = True              pos : neg    =      7.9 : 1.0\n",
      "                  bother = True              neg : pos    =      7.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4186,
     "status": "ok",
     "timestamp": 1742803018076,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "ct8PZm9qJXMa",
    "outputId": "9a04fa9a-6646-418e-d416-27aa6866d3f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet, names\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import pos_tag\n",
    "import random\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1742803280629,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "uS0yi-6-KF58",
    "outputId": "54d5609b-b3f6-4f3c-bb39-6860a444ac42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toolbox', 'dependency_treebank', 'abc.zip', 'udhr.zip', 'paradigms', 'kimmo.zip', 'floresta', 'english_wordnet', 'indian', 'framenet_v15.zip', 'crubadan.zip', 'wordnet_ic', 'shakespeare', 'mte_teip5.zip', 'toolbox.zip', 'qc', 'knbc.zip', 'senseval', 'udhr2.zip', 'names.zip', 'product_reviews_1', 'pil', 'stopwords.zip', 'timit', 'propbank.zip', 'cess_cat', 'omw.zip', 'state_union.zip', 'nonbreaking_prefixes', 'product_reviews_1.zip', 'udhr2', 'reuters.zip', 'opinion_lexicon', 'jeita.zip', 'conll2000', 'kimmo', 'chat80', 'biocreative_ppi.zip', 'comtrans.zip', 'pil.zip', 'english_wordnet.zip', 'shakespeare.zip', 'stopwords', 'wordnet2021.zip', 'indian.zip', 'sentiwordnet.zip', 'inaugural', 'brown_tei', 'ycoe', 'framenet_v17', 'gazetteers.zip', 'wordnet.zip', 'comparative_sentences.zip', 'pros_cons.zip', 'conll2002.zip', 'words', 'problem_reports', 'genesis', 'lin_thesaurus', 'europarl_raw', 'conll2002', 'sinica_treebank.zip', 'opinion_lexicon.zip', 'mac_morpho.zip', 'rte', 'comparative_sentences', 'brown_tei.zip', 'switchboard.zip', 'switchboard', 'treebank', 'masc_tagged.zip', 'webtext.zip', 'wordnet31.zip', 'conll2000.zip', 'wordnet2022.zip', 'crubadan', 'twitter_samples', 'floresta.zip', 'verbnet3.zip', 'smultron.zip', 'brown.zip', 'gutenberg', 'extended_omw.zip', 'wordnet2022', 'abc', 'omw-1.4.zip', 'timit.zip', 'chat80.zip', 'rte.zip', 'words.zip', 'product_reviews_2', 'cess_cat.zip', 'sinica_treebank', 'ppattach', 'dolch.zip', 'webtext', 'unicode_samples', 'mte_teip5', 'sentence_polarity', 'pe08', 'machado.zip', 'semcor.zip', 'panlex_swadesh.zip', 'problem_reports.zip', 'lin_thesaurus.zip', 'gutenberg.zip', 'pe08.zip', 'twitter_samples.zip', 'bcp47.zip', 'genesis.zip', 'verbnet.zip', 'ieer.zip', 'cmudict.zip', 'sentence_polarity.zip', 'ptb', 'qc.zip', 'product_reviews_2.zip', 'unicode_samples.zip', 'nonbreaking_prefixes.zip', 'city_database', 'verbnet', 'pl196x', 'nps_chat.zip', 'verbnet3', 'cess_esp.zip', 'swadesh', 'names', 'paradigms.zip', 'smultron', 'nps_chat', 'brown', 'biocreative_ppi', 'wordnet_ic.zip', 'ycoe.zip', 'inaugural.zip', 'subjectivity', 'cmudict', 'framenet_v15', 'ppattach.zip', 'movie_reviews', 'pl196x.zip', 'ieer', 'framenet_v17.zip', 'cess_esp', 'alpino.zip', 'state_union', 'mac_morpho', 'conll2007.zip', 'universal_treebanks_v20.zip', 'senseval.zip', 'gazetteers', 'nombank.1.0.zip', 'sentiwordnet', 'udhr', 'dolch', 'treebank.zip', 'swadesh.zip', 'subjectivity.zip', 'ptb.zip', 'alpino', 'pros_cons', 'city_database.zip', 'movie_reviews.zip', 'dependency_treebank.zip', 'europarl_raw.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.data import find\n",
    "corpus_path = find(\"corpora\")\n",
    "print(os.listdir(corpus_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1742803415948,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "lynDz37tLI56",
    "outputId": "f27350ed-b92d-44ef-cb73-174515113a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'tamil', 'turkish']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1742803504691,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "RSILjwDeLj5H",
    "outputId": "b49ea528-cdcd-4947-81af-11763da55698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1742806381776,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "-dxENytRL3k6",
    "outputId": "feb27583-1a8d-446c-e662-9572f5c7286d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "words = word_tokenize(text)\n",
    "filtered = [w for w in words if w.lower() not in stopwords.words('english')]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1742809843838,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "14G_YqNLW-QL",
    "outputId": "4e34eda7-5629-4a9a-f751-9fb8d4b8a39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'nltk', ' it', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "custom_list = ['i', 'am', 'learning', 'nltk', 'and','it', 'is','awesome']\n",
    "filtered_custom = [w for w in custom_list if w not in stopwords.words('english')]\n",
    "print(filtered_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1742810212618,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "b9i1Td7bkMTm",
    "outputId": "410836c5-ccd8-4f31-ee3c-712124b8abaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Định nghĩa:  a machine for performing calculations automatically\n",
      "Ví dụ:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "word = 'computer'\n",
    "syns = wn.synsets(word)\n",
    "for s in syns[:1]:\n",
    "  print(\"Định nghĩa: \", s.definition())\n",
    "  print(\"Ví dụ: \", s.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1742810451614,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "f-JdfdhmkXFC",
    "outputId": "60da8266-d621-4ce4-a18c-80eab0758f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đồng nghĩa của 'good':  ['serious', 'unspoilt', 'in_effect', 'thoroughly', 'secure', 'expert', 'well', 'unspoiled', 'good', 'trade_good']\n",
      "Trái nghĩa của 'good':  ['badness', 'evil', 'bad', 'evilness', 'ill']\n"
     ]
    }
   ],
   "source": [
    "synonyms = set()\n",
    "antonyms = set()\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.add(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.add(l.antonyms()[0].name())\n",
    "print(\"Đồng nghĩa của 'good': \", list(synonyms)[:10])\n",
    "print(\"Trái nghĩa của 'good': \", list(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1742810561578,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "mz4GghjOmaf4",
    "outputId": "600ad2c0-0cf2-4e2b-8014-be93a64620da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1742810687535,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "_fPMkXC0mxO4",
    "outputId": "bb59b099-940f-4080-e1c6-058dabd02772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mức độ tương đồng giữa car và bus:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('car.n.01')\n",
    "w2 = wordnet.synset('bus.n.01')\n",
    "print(\"Mức độ tương đồng giữa car và bus: \", w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1742810795592,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "PA1DrZ6onSYI",
    "outputId": "3e93b29e-de9b-4d59-9289-ad2d43a79038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mức độ tương đồng giữa run và walk:  0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "v1 = wordnet.synset('run.v.01')\n",
    "v2 = wordnet.synset('walk.v.01')\n",
    "print(\"Mức độ tương đồng giữa run và walk: \", v1.wup_similarity(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1742810944288,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "EWSChdRHnqmK",
    "outputId": "8f50ff45-d8c3-4aef-b6fb-3c365b713f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng tên nam:  2943\n",
      "Số lượng tên nữ:  5001\n",
      "10 tên nam đầu tiên:  ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "10 tên nữ đầu tiên:  ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /root/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('names')\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "print(\"Số lượng tên nam: \", len(male_names))\n",
    "print(\"Số lượng tên nữ: \", len(female_names))\n",
    "print(\"10 tên nam đầu tiên: \", male_names[:10])\n",
    "print(\"10 tên nữ đầu tiên: \", female_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1742811423983,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "GP-MPEwBoQ5p",
    "outputId": "93614572-4729-4902-dc2b-6833b3b1b84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 tên ngẫu nhiên (nam/nữ)\n",
      "[('Wake', 'male'), ('Pavel', 'male'), ('Pavla', 'female'), ('Cordelia', 'female'), ('Vale', 'male'), ('Arly', 'female'), ('Garcia', 'male'), ('Franni', 'female'), ('Hanni', 'female'), ('Vilhelmina', 'female'), ('Claudie', 'female'), ('Fonzie', 'male'), ('Judd', 'male'), ('Mariele', 'female'), ('Katti', 'female')]\n"
     ]
    }
   ],
   "source": [
    "labled_names = ([(name, 'male') for name in male_names] + [(name, 'female') for name in female_names])\n",
    "random.shuffle(labled_names)\n",
    "print(\"15 tên ngẫu nhiên (nam/nữ)\")\n",
    "print(labled_names[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1742811461933,
     "user": {
      "displayName": "Kiệt Châu",
      "userId": "16317023568719289571"
     },
     "user_tz": -420
    },
    "id": "wWlH5K3rpUiA",
    "outputId": "37f2aa01-1456-4ba0-e0ef-de5fc610eb26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mảng (ký tự cuối, nhãn)\n",
      "[('e', 'male'), ('l', 'male'), ('a', 'female'), ('a', 'female'), ('e', 'male'), ('y', 'female'), ('a', 'male'), ('i', 'female'), ('i', 'female'), ('a', 'female'), ('e', 'female'), ('e', 'male'), ('d', 'male'), ('e', 'female'), ('i', 'female')]\n"
     ]
    }
   ],
   "source": [
    "features = [(name[-1], gender) for (name, gender) in labled_names]\n",
    "print(\"Mảng (ký tự cuối, nhãn)\")\n",
    "print(features[:15])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlLsJrUWIGU0JYoV9OqQ/N",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
